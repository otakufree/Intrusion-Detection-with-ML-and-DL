# -*- coding: utf-8 -*-
"""Intrusion Detection System with ML&DL

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ADfAYflWhAmzcKsWwY0wCW2oKyzpJMmR
"""

import kagglehub
hassan06_nslkdd_path = kagglehub.dataset_download('hassan06/nslkdd')

print('Data source import complete.')

"""## Importing necessary libraries"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import warnings
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras import regularizers
import xgboost as xgb
from sklearn.decomposition import PCA
from sklearn import tree
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import RobustScaler
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn import svm
from sklearn import metrics
pd.set_option('display.max_columns',None)
warnings.filterwarnings('ignore')
# %matplotlib inline

"""## Exploring the dataset"""

data_train = pd.read_csv(f"{hassan06_nslkdd_path}/KDDTrain+.txt")

data_train.head()

columns = (['duration','protocol_type','service','flag','src_bytes','dst_bytes','land','wrong_fragment','urgent','hot'
,'num_failed_logins','logged_in','num_compromised','root_shell','su_attempted','num_root','num_file_creations'
,'num_shells','num_access_files','num_outbound_cmds','is_host_login','is_guest_login','count','srv_count','serror_rate'
,'srv_serror_rate','rerror_rate','srv_rerror_rate','same_srv_rate','diff_srv_rate','srv_diff_host_rate','dst_host_count','dst_host_srv_count'
,'dst_host_same_srv_rate','dst_host_diff_srv_rate','dst_host_same_src_port_rate','dst_host_srv_diff_host_rate','dst_host_serror_rate'
,'dst_host_srv_serror_rate','dst_host_rerror_rate','dst_host_srv_rerror_rate','outcome','level'])

data_train.columns = columns

data_train.head()

data_train.info()

data_train.describe().style.background_gradient(cmap='Blues').set_properties(**{'font-family':'Segoe UI'})

data_train.loc[data_train['outcome'] == "normal", "outcome"] = 'normal'
data_train.loc[data_train['outcome'] != 'normal', "outcome"] = 'attack'

def pie_plot(df, cols_list, rows, cols):
    fig, axes = plt.subplots(rows, cols)
    for ax, col in zip(axes.ravel(), cols_list):
        df[col].value_counts().plot(ax=ax, kind='pie', figsize=(15, 15), fontsize=10, autopct='%1.0f%%')
        ax.set_title(str(col), fontsize = 12)
    plt.show()

pie_plot(data_train, ['protocol_type', 'outcome'], 1, 2)

"""## Preprocessing the data"""

def Scaling(df_num, cols):
    std_scaler = RobustScaler()
    std_scaler_temp = std_scaler.fit_transform(df_num)
    std_df = pd.DataFrame(std_scaler_temp, columns =cols)
    return std_df

cat_cols = ['is_host_login','protocol_type','service','flag','land', 'logged_in','is_guest_login', 'level', 'outcome']
def preprocess(dataframe):
    df_num = dataframe.drop(cat_cols, axis=1)
    num_cols = df_num.columns
    scaled_df = Scaling(df_num, num_cols)

    dataframe.drop(labels=num_cols, axis="columns", inplace=True)
    dataframe[num_cols] = scaled_df[num_cols]

    dataframe.loc[dataframe['outcome'] == "normal", "outcome"] = 0
    dataframe.loc[dataframe['outcome'] != 0, "outcome"] = 1

    dataframe = pd.get_dummies(dataframe, columns = ['protocol_type', 'service', 'flag'])
    return dataframe

scaled_train = preprocess(data_train)

"""Principal Component Analysis



"""

x = scaled_train.drop(['outcome', 'level'] , axis = 1).values
y = scaled_train['outcome'].values
y_reg = scaled_train['level'].values

pca = PCA(n_components=20)
pca = pca.fit(x)
x_reduced = pca.transform(x)
print("Number of original features is {} and of reduced features is {}".format(x.shape[1], x_reduced.shape[1]))

y = y.astype('int')
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
x_train_reduced, x_test_reduced, y_train_reduced, y_test_reduced = train_test_split(x_reduced, y, test_size=0.2, random_state=42)
x_train_reg, x_test_reg, y_train_reg, y_test_reg = train_test_split(x, y_reg, test_size=0.2, random_state=42)

kernal_evals = dict()
def evaluate_classification(model, name, X_train, X_test, y_train, y_test):
    train_accuracy = metrics.accuracy_score(y_train, model.predict(X_train))
    test_accuracy = metrics.accuracy_score(y_test, model.predict(X_test))

    train_precision = metrics.precision_score(y_train, model.predict(X_train))
    test_precision = metrics.precision_score(y_test, model.predict(X_test))

    train_recall = metrics.recall_score(y_train, model.predict(X_train))
    test_recall = metrics.recall_score(y_test, model.predict(X_test))

    kernal_evals[str(name)] = [train_accuracy, test_accuracy, train_precision, test_precision, train_recall, test_recall]
    print("Training Accuracy " + str(name) + " {}  Test Accuracy ".format(train_accuracy*100) + str(name) + " {}".format(test_accuracy*100))
    print("Training Precesion " + str(name) + " {}  Test Precesion ".format(train_precision*100) + str(name) + " {}".format(test_precision*100))
    print("Training Recall " + str(name) + " {}  Test Recall ".format(train_recall*100) + str(name) + " {}".format(test_recall*100))

    actual = y_test
    predicted = model.predict(X_test)
    confusion_matrix = metrics.confusion_matrix(actual, predicted)
    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = ['normal', 'attack'])

    fig, ax = plt.subplots(figsize=(10,10))
    ax.grid(False)
    cm_display.plot(ax=ax)

"""## Modeling

Logistic Regression
"""

lr = LogisticRegression().fit(x_train, y_train)
evaluate_classification(lr, "Logistic Regression", x_train, x_test, y_train, y_test)

""" Naive Bayes

"""

gnb = GaussianNB().fit(x_train, y_train)
evaluate_classification(gnb, "GaussianNB", x_train, x_test, y_train, y_test)

""" Support Vector Machines


"""

lin_svc = svm.LinearSVC().fit(x_train, y_train)

evaluate_classification(lin_svc, "Linear SVC(LBasedImpl)", x_train, x_test, y_train, y_test)

""" Decision Tree

"""

dt = DecisionTreeClassifier(max_depth=3).fit(x_train, y_train)
tdt = DecisionTreeClassifier().fit(x_train, y_train)
evaluate_classification(tdt, "DecisionTreeClassifier", x_train, x_test, y_train, y_test)

def f_importances(coef, names, top=-1):
    imp = coef
    imp, names = zip(*sorted(list(zip(imp, names))))

    # Show all features
    if top == -1:
        top = len(names)

    plt.figure(figsize=(10,10))
    plt.barh(range(top), imp[::-1][0:top], align='center')
    plt.yticks(range(top), names[::-1][0:top])
    plt.title('feature importances for Decision Tree')
    plt.show()

features_names = data_train.drop(['outcome', 'level'] , axis = 1)
f_importances(abs(tdt.feature_importances_), features_names, top=18)

fig = plt.figure(figsize=(15,12))
tree.plot_tree(dt , filled=True)

"""Random forest


"""

rf = RandomForestClassifier().fit(x_train, y_train)
evaluate_classification(rf, "RandomForestClassifier", x_train, x_test, y_train, y_test)

f_importances(abs(rf.feature_importances_), features_names, top=18)

"""## Building an XGBOOST REgressor regressor in order to predict threat level"""

xg_r = xgb.XGBRegressor(objective ='reg:squarederror',n_estimators = 20).fit(x_train_reg, y_train_reg)

name = "XGBOOST"
train_mse = metrics.mean_squared_error(y_train_reg, xg_r.predict(x_train_reg))
test_mse = metrics.mean_squared_error(y_test_reg, xg_r.predict(x_test_reg))
train_error = np.sqrt(train_mse)
test_error = np.sqrt(test_mse)

print("Training Error " + str(name) + " {}  Test error ".format(train_error) + str(name) + " {}".format(test_error))

"""## Measuring effect of PCA"""

rrf = RandomForestClassifier().fit(x_train_reduced, y_train_reduced)
evaluate_classification(rrf, "PCA RandomForest", x_train_reduced, x_test_reduced, y_train_reduced, y_test_reduced)

"""## Neural networks


"""

model = tf.keras.Sequential([
    tf.keras.layers.Dense(units=64, activation='relu', input_shape=(x_train.shape[1:]),
                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),
                          bias_regularizer=regularizers.L2(1e-4),
                          activity_regularizer=regularizers.L2(1e-5)),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(units=128, activation='relu',
                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),
                          bias_regularizer=regularizers.L2(1e-4),
                          activity_regularizer=regularizers.L2(1e-5)),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(units=512, activation='relu',
                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),
                          bias_regularizer=regularizers.L2(1e-4),
                          activity_regularizer=regularizers.L2(1e-5)),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(units=128, activation='relu',
                          kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),
                          bias_regularizer=regularizers.L2(1e-4),
                          activity_regularizer=regularizers.L2(1e-5)),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(units=1, activation='sigmoid'),
])

model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=['accuracy'])

model.summary()

!pip install pydot graphviz
import tensorflow as tf # Ensure tensorflow is imported if not already
from tensorflow import keras # Import keras from tensorflow
from keras.utils import plot_model
# Continue with the rest of your code to define and compile the model
# ...
# Then plot the model
plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)

"""LSTM (Long Short-Term Memory"""

from keras.models import Sequential
from keras.layers import LSTM, Dense
from keras.utils import to_categorical
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# One-hot encode the labels
y_train_cat = to_categorical(y_train)
y_test_cat = to_categorical(y_test)

# Reshape input for LSTM [samples, time_steps, features]
# Changed X_train to x_train and X_test to x_test
X_train_dl = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))
X_test_dl = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))

# Explicitly convert data types to float32
X_train_dl = X_train_dl.astype('float32')
X_test_dl = X_test_dl.astype('float32')
y_train_cat = y_train_cat.astype('float32')
y_test_cat = y_test_cat.astype('float32')


# Build LSTM model
lstm = Sequential()
# Changed X_train.shape[1] to x_train.shape[1]
lstm.add(LSTM(64, input_shape=(1, x_train.shape[1]), activation='relu'))
lstm.add(Dense(2, activation='softmax'))  # 2 output units for binary classification
lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
lstm.fit(X_train_dl, y_train_cat, epochs=5, batch_size=128, verbose=0)

# Predict and evaluate
y_pred_lstm = np.argmax(lstm.predict(X_test_dl), axis=1)

# Ensure 'results' list is defined. If it's not defined in a previous cell,
# you'll need to initialize it before this cell runs.
# For example, add: results = [] in a preceding cell or at the start of this cell.
# Added a check and initialization for 'results' if it doesn't exist.
try:
    results
except NameError:
    results = []
results.append(["LSTM"] + [
    round(accuracy_score(y_test, y_pred_lstm) * 100, 2),
    round(precision_score(y_test, y_pred_lstm) * 100, 2),
    round(recall_score(y_test, y_pred_lstm) * 100, 2),
    round(f1_score(y_test, y_pred_lstm) * 100, 2)
])

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import LSTM, Dense # Import LSTM and Dense
import matplotlib.pyplot as plt

# Assuming x_train, x_test, y_train, y_test are already defined from previous cells

# One-hot encode the labels
y_train_cat = to_categorical(y_train)
y_test_cat = to_categorical(y_test)

# Reshape input for LSTM [samples, time_steps, features]
X_train_dl = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))
X_test_dl = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))

# Explicitly convert data types to float32
X_train_dl = X_train_dl.astype('float32')
X_test_dl = X_test_dl.astype('float32')
y_train_cat = y_train_cat.astype('float32')
y_test_cat = y_test_cat.astype('float32')

# Build LSTM model
lstm = Sequential()
lstm.add(LSTM(64, input_shape=(1, x_train.shape[1]), activation='relu'))
lstm.add(Dense(2, activation='softmax')) # 2 output units for binary classification
lstm.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
lstm.fit(X_train_dl, y_train_cat, epochs=5, batch_size=128, verbose=0)

# Predict probabilities and class labels
y_pred_prob_lstm = lstm.predict(X_test_dl)
y_pred_lstm = np.argmax(y_pred_prob_lstm, axis=1)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred_lstm)
precision = precision_score(y_test, y_pred_lstm)
recall = recall_score(y_test, y_pred_lstm)
f1 = f1_score(y_test, y_pred_lstm)

print(f"LSTM Accuracy: {accuracy:.4f}")
print(f"LSTM Precision: {precision:.4f}")
print(f"LSTM Recall: {recall:.4f}")
print(f"LSTM F1-score: {f1:.4f}")

# Append to results list if it exists
try:
    results.append(["LSTM"] + [
        round(accuracy * 100, 2),
        round(precision * 100, 2),
        round(recall * 100, 2),
        round(f1 * 100, 2)
    ])
except NameError:
    print("\n'results' list not found. Metrics were printed above.")


# --- ROC Curve ---
# Get predicted probabilities for the positive class (class 1)
y_pred_prob_positive_lstm = y_pred_prob_lstm[:, 1]

# Compute ROC curve and ROC area
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_positive_lstm)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - LSTM')
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()

# --- Confusion Matrix ---
actual = y_test
predicted = y_pred_lstm
confusion_mat = confusion_matrix(actual, predicted)
cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_mat, display_labels = ['normal', 'attack'])

fig, ax = plt.subplots(figsize=(10,10))
ax.grid(False) # Turn off grid for confusion matrix plot
cm_display.plot(ax=ax)
plt.title('Confusion Matrix - LSTM')
plt.show()

"""RNN (Recurrent Neural Network)"""

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import LSTM, Dense, SimpleRNN # Import SimpleRNN

y_train_cat = to_categorical(y_train)
y_test_cat = to_categorical(y_test)

# Use x_train and x_test which are defined in previous cells
X_train_dl = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))
X_test_dl = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))

# Explicitly convert data types to float32 if needed, although they should be from previous cells
X_train_dl = X_train_dl.astype('float32')
X_test_dl = X_test_dl.astype('float32')
y_train_cat = y_train_cat.astype('float32')
y_test_cat = y_test_cat.astype('float32')


rnn = Sequential()
# Use x_train.shape[1] for input_shape
rnn.add(SimpleRNN(64, input_shape=(1, x_train.shape[1]), activation='relu'))
rnn.add(Dense(2, activation='softmax'))
rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
rnn.fit(X_train_dl, y_train_cat, epochs=5, batch_size=128, verbose=0)

y_pred = np.argmax(rnn.predict(X_test_dl), axis=1)

# Ensure 'results' list is defined if you want to append to it.
# If not defined elsewhere, initialize it before this cell.
try:
    results.append(["RNN"] + [
        round(accuracy_score(y_test, y_pred)*100, 2),
        round(precision_score(y_test, y_pred)*100, 2),
        round(recall_score(y_test, y_pred)*100, 2),
        round(f1_score(y_test, y_pred)*100, 2)
    ])
except NameError:
    # If results list is not found, just print the metrics
    print(f"RNN Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}")
    print(f"RNN Precision: {precision_score(y_test, y_pred)*100:.2f}")
    print(f"RNN Recall: {recall_score(y_test, y_pred)*100:.2f}")
    print(f"RNN F1-score: {f1_score(y_test, y_pred)*100:.2f}")
    print("\n'results' list not found. Metrics were printed above.")
    print("If you intended to append to 'results', initialize it before this cell.")

import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import SimpleRNN, Dense
import matplotlib.pyplot as plt

# Assuming x_train, x_test, y_train, y_test are already defined from previous cells

# One-hot encode the labels
y_train_cat = to_categorical(y_train)
y_test_cat = to_categorical(y_test)

# Reshape input for RNN [samples, time_steps, features]
X_train_dl = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))
X_test_dl = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))

# Explicitly convert data types to float32
X_train_dl = X_train_dl.astype('float32')
X_test_dl = X_test_dl.astype('float32')
y_train_cat = y_train_cat.astype('float32')
y_test_cat = y_test_cat.astype('float32')

# Build SimpleRNN model
rnn = Sequential()
rnn.add(SimpleRNN(64, input_shape=(1, x_train.shape[1]), activation='relu'))
rnn.add(Dense(2, activation='softmax')) # 2 output units for binary classification
rnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train model
rnn.fit(X_train_dl, y_train_cat, epochs=5, batch_size=128, verbose=0)

# Predict probabilities and class labels
y_pred_prob_rnn = rnn.predict(X_test_dl)
y_pred_rnn = np.argmax(y_pred_prob_rnn, axis=1)

# Calculate metrics
accuracy = accuracy_score(y_test, y_pred_rnn)
precision = precision_score(y_test, y_pred_rnn)
recall = recall_score(y_test, y_pred_rnn)
f1 = f1_score(y_test, y_pred_rnn)

print(f"RNN Accuracy: {accuracy:.4f}")
print(f"RNN Precision: {precision:.4f}")
print(f"RNN Recall: {recall:.4f}")
print(f"RNN F1-score: {f1:.4f}")

# Append to results list if it exists
try:
    results.append(["RNN"] + [
        round(accuracy * 100, 2),
        round(precision * 100, 2),
        round(recall * 100, 2),
        round(f1 * 100, 2)
    ])
except NameError:
    print("\n'results' list not found. Metrics were printed above.")


# --- ROC Curve ---
# Get predicted probabilities for the positive class (class 1)
y_pred_prob_positive_rnn = y_pred_prob_rnn[:, 1]

# Compute ROC curve and ROC area
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_positive_rnn)
roc_auc = auc(fpr, tpr)

# Plot ROC curve
plt.figure(figsize=(8, 8))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve - SimpleRNN')
plt.legend(loc="lower right")
plt.grid(True)
plt.tight_layout()
plt.show()

# --- Confusion Matrix ---
actual = y_test
predicted = y_pred_rnn
confusion_mat = confusion_matrix(actual, predicted)
cm_display = ConfusionMatrixDisplay(confusion_matrix = confusion_mat, display_labels = ['normal', 'attack'])

fig, ax = plt.subplots(figsize=(10,10))
ax.grid(False) # Turn off grid for confusion matrix plot
cm_display.plot(ax=ax)
plt.title('Confusion Matrix - SimpleRNN')
plt.show()

"""Comparing results and Conclusion"""

keys = [key for key in kernal_evals.keys()]
values = [value for value in kernal_evals.values()]
fig, ax = plt.subplots(figsize=(20, 6))
ax.bar(np.arange(len(keys)) - 0.2, [value[0] for value in values], color='darkred', width=0.25, align='center')
ax.bar(np.arange(len(keys)) + 0.2, [value[1] for value in values], color='y', width=0.25, align='center')
ax.legend(["Training Accuracy", "Test Accuracy"])
ax.set_xticklabels(keys)
ax.set_xticks(np.arange(len(keys)))
plt.ylabel("Accuracy")
plt.show()

keys = [key for key in kernal_evals.keys()]
values = [value for value in kernal_evals.values()]
fig, ax = plt.subplots(figsize=(20, 6))
ax.bar(np.arange(len(keys)) - 0.2, [value[2] for value in values], color='g', width=0.25, align='center')
ax.bar(np.arange(len(keys)) + 0.2, [value[3] for value in values], color='b', width=0.25, align='center')
ax.legend(["Training Precesion", "Test Presision"])
ax.set_xticklabels(keys)
ax.set_xticks(np.arange(len(keys)))
plt.ylabel("Precesion")
plt.show()

keys = [key for key in kernal_evals.keys()]
values = [value for value in kernal_evals.values()]
fig, ax = plt.subplots(figsize=(20, 6))
ax.bar(np.arange(len(keys)) - 0.2, [value[2] for value in values], color='g', width=0.25, align='center')
ax.bar(np.arange(len(keys)) + 0.2, [value[3] for value in values], color='b', width=0.25, align='center')
ax.legend(["Training Recall", "Test Recall"])
ax.set_xticklabels(keys)
ax.set_xticks(np.arange(len(keys)))
plt.ylabel("Recall")
plt.show()